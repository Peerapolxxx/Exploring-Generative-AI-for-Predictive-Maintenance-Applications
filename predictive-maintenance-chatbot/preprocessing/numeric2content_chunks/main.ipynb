{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_chunking_corpus(prepared_data_dir):\n",
    "    # อ่านรายชื่อโรงงาน\n",
    "    file_name = \"plant_list.csv\"\n",
    "    plant_list_file = os.path.join(prepared_data_dir, file_name)\n",
    "    if os.path.isfile(plant_list_file):\n",
    "        plant_df = pd.read_csv(plant_list_file)\n",
    "        # plant_df = plant_df[0:1]\n",
    "        # plant_df = plant_df[1:2]\n",
    "    else:\n",
    "        print(f\":: Failed ❌\")\n",
    "        print(f\"File not found: {plant_list_file}\")\n",
    "        return  # หยุดการทำงานของฟังก์ชัน\n",
    "\n",
    "    for _, plant_row in plant_df.iterrows():\n",
    "        plant_tag = plant_row[\"PLANT_TAG\"]\n",
    "        plant_name = plant_row[\"PLANT_NAME\"]\n",
    "\n",
    "        # อ่านรายชื่อเครื่องจักรสำหรับแต่ละโรงงาน\n",
    "        file_name = \"machine_list.csv\"\n",
    "        machine_list_file = os.path.join(prepared_data_dir, plant_tag, file_name)\n",
    "        if os.path.isfile(machine_list_file):\n",
    "            machine_df = pd.read_csv(machine_list_file)\n",
    "        else:\n",
    "            print(f\":: Failed ❌\")\n",
    "            print(f\"File not found: {machine_list_file}\")\n",
    "            break\n",
    "\n",
    "        for idx, machine_row in machine_df.iterrows():\n",
    "            machine_tag = machine_row[\"MACHINE_TAG\"]\n",
    "            machine_name = machine_row[\"MACHINE_NAME\"]\n",
    "            chunks_content_list = []\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 100)\n",
    "            print(\n",
    "                f\"#{idx+1} Processing data for {plant_name} (TAG: {plant_tag}) - {machine_name} (TAG: {machine_tag})\"\n",
    "            )\n",
    "            print(\"=\" * 100)\n",
    "\n",
    "            # ประมวลผลข้อมูลข้อความ corpus\n",
    "            file_name = f\"{plant_tag}_{machine_tag}_corpus.txt\"\n",
    "            print(f\"\\n>> Process: Corpus text dataa - File: {file_name}\")\n",
    "            corpus_file = os.path.join(prepared_data_dir, plant_tag, machine_tag, file_name)\n",
    "            if os.path.isfile(corpus_file):\n",
    "                with open(corpus_file, \"r\") as file:\n",
    "                    corpus_content = file.read()\n",
    "\n",
    "                print(\":: Complete ✔️\")\n",
    "                # print(corpus_text)\n",
    "            else:\n",
    "                print(f\":: Failed ❌\")\n",
    "                print(f\"File not found: {corpus_file}\")\n",
    "                corpus_content = \"\"\n",
    "                \n",
    "            # แบ่งเนื้อหาเป็นชิ้นๆ\n",
    "            print(f\"\\n>> Chunks content\")\n",
    "            # bullet_list_pattern = r\"\\* (.*?)\\n\"\n",
    "            bullet_list_pattern = r\"\\* (.+?)(?=\\n|\\Z)\"\n",
    "            chunks_content = re.findall(bullet_list_pattern, corpus_content)\n",
    "            chunks_content_list.extend(chunks_content)\n",
    "            \n",
    "            doc_id = f\"{plant_tag}_{machine_tag}\"\n",
    "            namespace = uuid.NAMESPACE_DNS\n",
    "\n",
    "            # สร้าง UUID เวอร์ชัน 3\n",
    "            uuid3 = uuid.uuid3(namespace, doc_id)\n",
    "            metadata = [{\n",
    "                \"doc_id\": doc_id,\n",
    "                \"original_uuid\": str(uuid3),\n",
    "                \"corpus_source\": corpus_file,\n",
    "                \"chunks\": [\n",
    "                    {\n",
    "                        \"chunk_id\": f\"{doc_id}_chunk_{idx}\",\n",
    "                        \"original_index\": idx,\n",
    "                        \"content\": content\n",
    "                    }\n",
    "                    for idx, content in enumerate(chunks_content_list)\n",
    "                ]\n",
    "            }]\n",
    "            print(f\":: Complete ✔️\") \n",
    "            \n",
    "            # ประมวลผลการบันทึกไปยัง prepared_data_dir\n",
    "            file_name = f\"{plant_tag}_{machine_tag}_chunks.json\"\n",
    "\n",
    "            # ตรวจสอบและสร้าง directory หากยังไม่มีอยู่\n",
    "            save_to_dir = os.path.join(prepared_data_dir, plant_tag, machine_tag)\n",
    "            os.makedirs(save_to_dir, exist_ok=True)\n",
    "\n",
    "            # สร้าง path ของไฟล์สุดท้าย\n",
    "            chunks_content_full_file_path = os.path.join(save_to_dir, file_name)\n",
    "            \n",
    "            # บันทึก JSON ที่สร้างได้ลงไฟล์\n",
    "            with open(chunks_content_full_file_path, \"w\") as f:\n",
    "                json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(\"\\n>> JSON file created successfully.\")\n",
    "            print(f\":: File name: {file_name}\")\n",
    "            print(f\":: Data successfully saved to: {chunks_content_full_file_path}\")\n",
    "            print(f\":: Complete ✔️\")\n",
    "\n",
    "            print(\"=\" * 100)\n",
    "            print(\"Complete all Process\")\n",
    "            print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "#1 Processing data for Natural Gas Processing Plant (TAG: PLANT_01) - Sale Gas Compressor (TAG: COMP_SG01)\n",
      "====================================================================================================\n",
      "\n",
      ">> Process: Corpus text dataa - File: PLANT_01_COMP_SG01_corpus.txt\n",
      ":: Complete ✔️\n",
      "\n",
      ">> Chunks content\n",
      ":: Complete ✔️\n",
      "\n",
      ">> JSON file created successfully.\n",
      ":: File name: PLANT_01_COMP_SG01_chunks.json\n",
      ":: Data successfully saved to: D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\\predictive-maintenance-chatbot\\data\\prepared_data\\PLANT_01\\COMP_SG01\\PLANT_01_COMP_SG01_chunks.json\n",
      ":: Complete ✔️\n",
      "====================================================================================================\n",
      "Complete all Process\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "#1 Processing data for Everflow Utility Plant (TAG: PLANT_02) - Dual Fuel Generator A (TAG: GEN_DF_01)\n",
      "====================================================================================================\n",
      "\n",
      ">> Process: Corpus text dataa - File: PLANT_02_GEN_DF_01_corpus.txt\n",
      ":: Complete ✔️\n",
      "\n",
      ">> Chunks content\n",
      ":: Complete ✔️\n",
      "\n",
      ">> JSON file created successfully.\n",
      ":: File name: PLANT_02_GEN_DF_01_chunks.json\n",
      ":: Data successfully saved to: D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\\predictive-maintenance-chatbot\\data\\prepared_data\\PLANT_02\\GEN_DF_01\\PLANT_02_GEN_DF_01_chunks.json\n",
      ":: Complete ✔️\n",
      "====================================================================================================\n",
      "Complete all Process\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "#2 Processing data for Everflow Utility Plant (TAG: PLANT_02) - Dual Fuel Generator B (TAG: GEN_DF_02)\n",
      "====================================================================================================\n",
      "\n",
      ">> Process: Corpus text dataa - File: PLANT_02_GEN_DF_02_corpus.txt\n",
      ":: Complete ✔️\n",
      "\n",
      ">> Chunks content\n",
      ":: Complete ✔️\n",
      "\n",
      ">> JSON file created successfully.\n",
      ":: File name: PLANT_02_GEN_DF_02_chunks.json\n",
      ":: Data successfully saved to: D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\\predictive-maintenance-chatbot\\data\\prepared_data\\PLANT_02\\GEN_DF_02\\PLANT_02_GEN_DF_02_chunks.json\n",
      ":: Complete ✔️\n",
      "====================================================================================================\n",
      "Complete all Process\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "#3 Processing data for Everflow Utility Plant (TAG: PLANT_02) - Produce Water Injection Pump A (TAG: PMP_WI_01)\n",
      "====================================================================================================\n",
      "\n",
      ">> Process: Corpus text dataa - File: PLANT_02_PMP_WI_01_corpus.txt\n",
      ":: Complete ✔️\n",
      "\n",
      ">> Chunks content\n",
      ":: Complete ✔️\n",
      "\n",
      ">> JSON file created successfully.\n",
      ":: File name: PLANT_02_PMP_WI_01_chunks.json\n",
      ":: Data successfully saved to: D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\\predictive-maintenance-chatbot\\data\\prepared_data\\PLANT_02\\PMP_WI_01\\PLANT_02_PMP_WI_01_chunks.json\n",
      ":: Complete ✔️\n",
      "====================================================================================================\n",
      "Complete all Process\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "#4 Processing data for Everflow Utility Plant (TAG: PLANT_02) - Produce Water Injection Pump B (TAG: PMP_WI_02)\n",
      "====================================================================================================\n",
      "\n",
      ">> Process: Corpus text dataa - File: PLANT_02_PMP_WI_02_corpus.txt\n",
      ":: Complete ✔️\n",
      "\n",
      ">> Chunks content\n",
      ":: Complete ✔️\n",
      "\n",
      ">> JSON file created successfully.\n",
      ":: File name: PLANT_02_PMP_WI_02_chunks.json\n",
      ":: Data successfully saved to: D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\\predictive-maintenance-chatbot\\data\\prepared_data\\PLANT_02\\PMP_WI_02\\PLANT_02_PMP_WI_02_chunks.json\n",
      ":: Complete ✔️\n",
      "====================================================================================================\n",
      "Complete all Process\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "#5 Processing data for Everflow Utility Plant (TAG: PLANT_02) - Produce Water Injection Pump C (TAG: PMP_WI_03)\n",
      "====================================================================================================\n",
      "\n",
      ">> Process: Corpus text dataa - File: PLANT_02_PMP_WI_03_corpus.txt\n",
      ":: Complete ✔️\n",
      "\n",
      ">> Chunks content\n",
      ":: Complete ✔️\n",
      "\n",
      ">> JSON file created successfully.\n",
      ":: File name: PLANT_02_PMP_WI_03_chunks.json\n",
      ":: Data successfully saved to: D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\\predictive-maintenance-chatbot\\data\\prepared_data\\PLANT_02\\PMP_WI_03\\PLANT_02_PMP_WI_03_chunks.json\n",
      ":: Complete ✔️\n",
      "====================================================================================================\n",
      "Complete all Process\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "#6 Processing data for Everflow Utility Plant (TAG: PLANT_02) - Water process (TAG: SYS_WP_01)\n",
      "====================================================================================================\n",
      "\n",
      ">> Process: Corpus text dataa - File: PLANT_02_SYS_WP_01_corpus.txt\n",
      ":: Complete ✔️\n",
      "\n",
      ">> Chunks content\n",
      ":: Complete ✔️\n",
      "\n",
      ">> JSON file created successfully.\n",
      ":: File name: PLANT_02_SYS_WP_01_chunks.json\n",
      ":: Data successfully saved to: D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\\predictive-maintenance-chatbot\\data\\prepared_data\\PLANT_02\\SYS_WP_01\\PLANT_02_SYS_WP_01_chunks.json\n",
      ":: Complete ✔️\n",
      "====================================================================================================\n",
      "Complete all Process\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Set the project root directory.\n",
    "ROOT_DIRECTORY = \"D:\\Data_sci_internship\\Exploring Generative AI for Predictive Maintenance Applications\"\n",
    "\n",
    "# Specify the subpath project.\n",
    "PROJECT_DIRECTORY = \"predictive-maintenance-chatbot\"\n",
    "DATA_ROOT_DIRECTORY = \"data\"\n",
    "RAW_DATA_DIRECTORY = \"raw_data\"\n",
    "PREPARED_DATA_DIRECTORY = \"prepared_data\"\n",
    "\n",
    "prepared_data_dir = os.path.join(\n",
    "    ROOT_DIRECTORY, PROJECT_DIRECTORY, DATA_ROOT_DIRECTORY, PREPARED_DATA_DIRECTORY\n",
    ")\n",
    "\n",
    "# Call the pipeline_numeric2text function\n",
    "pipeline_chunking_corpus(prepared_data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PdM_RschAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
